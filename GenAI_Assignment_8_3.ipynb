{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRYYnMIsSdPlz0a6zyYxqX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niharshith-2044/GENERATIVE_AI_2303A52044/blob/main/GenAI_Assignment_8_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_STsdDHRA-dd",
        "outputId": "34f9f1c6-3827-4106-fc89-1ba0ca43b211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.5367 - loss: 0.6745 - val_accuracy: 0.5188 - val_loss: 0.6805\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5637 - loss: 0.6709 - val_accuracy: 0.5188 - val_loss: 0.6805\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5612 - loss: 0.6742 - val_accuracy: 0.5188 - val_loss: 0.6804\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5482 - loss: 0.6740 - val_accuracy: 0.5188 - val_loss: 0.6804\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5479 - loss: 0.6719 - val_accuracy: 0.5188 - val_loss: 0.6804\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5530 - loss: 0.6728 - val_accuracy: 0.5156 - val_loss: 0.6803\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5833 - loss: 0.6709 - val_accuracy: 0.5156 - val_loss: 0.6803\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5521 - loss: 0.6734 - val_accuracy: 0.5156 - val_loss: 0.6803\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5605 - loss: 0.6742 - val_accuracy: 0.5156 - val_loss: 0.6802\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5715 - loss: 0.6729 - val_accuracy: 0.5156 - val_loss: 0.6802\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5621 - loss: 0.6725 - val_accuracy: 0.5156 - val_loss: 0.6802\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5734 - loss: 0.6717 - val_accuracy: 0.5156 - val_loss: 0.6802\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5798 - loss: 0.6678 - val_accuracy: 0.5156 - val_loss: 0.6801\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5664 - loss: 0.6750 - val_accuracy: 0.5156 - val_loss: 0.6801\n",
            "Epoch 15/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5678 - loss: 0.6704 - val_accuracy: 0.5188 - val_loss: 0.6801\n",
            "Epoch 16/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5809 - loss: 0.6710 - val_accuracy: 0.5188 - val_loss: 0.6800\n",
            "Epoch 17/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5686 - loss: 0.6716 - val_accuracy: 0.5188 - val_loss: 0.6800\n",
            "Epoch 18/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5544 - loss: 0.6731 - val_accuracy: 0.5188 - val_loss: 0.6800\n",
            "Epoch 19/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5645 - loss: 0.6735 - val_accuracy: 0.5219 - val_loss: 0.6799\n",
            "Epoch 20/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5824 - loss: 0.6684 - val_accuracy: 0.5250 - val_loss: 0.6799\n",
            "Epoch 21/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5557 - loss: 0.6763 - val_accuracy: 0.5281 - val_loss: 0.6799\n",
            "Epoch 22/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5690 - loss: 0.6743 - val_accuracy: 0.5281 - val_loss: 0.6798\n",
            "Epoch 23/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5840 - loss: 0.6701 - val_accuracy: 0.5281 - val_loss: 0.6798\n",
            "Epoch 24/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5690 - loss: 0.6708 - val_accuracy: 0.5281 - val_loss: 0.6798\n",
            "Epoch 25/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5662 - loss: 0.6711 - val_accuracy: 0.5281 - val_loss: 0.6797\n",
            "Epoch 26/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5696 - loss: 0.6720 - val_accuracy: 0.5281 - val_loss: 0.6797\n",
            "Epoch 27/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5728 - loss: 0.6746 - val_accuracy: 0.5281 - val_loss: 0.6797\n",
            "Epoch 28/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5522 - loss: 0.6759 - val_accuracy: 0.5281 - val_loss: 0.6796\n",
            "Epoch 29/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5933 - loss: 0.6664 - val_accuracy: 0.5281 - val_loss: 0.6796\n",
            "Epoch 30/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5571 - loss: 0.6736 - val_accuracy: 0.5281 - val_loss: 0.6796\n",
            "Epoch 31/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5976 - loss: 0.6665 - val_accuracy: 0.5281 - val_loss: 0.6796\n",
            "Epoch 32/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5612 - loss: 0.6727 - val_accuracy: 0.5281 - val_loss: 0.6795\n",
            "Epoch 33/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5719 - loss: 0.6715 - val_accuracy: 0.5281 - val_loss: 0.6795\n",
            "Epoch 34/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5708 - loss: 0.6696 - val_accuracy: 0.5281 - val_loss: 0.6795\n",
            "Epoch 35/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5811 - loss: 0.6717 - val_accuracy: 0.5281 - val_loss: 0.6794\n",
            "Epoch 36/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5660 - loss: 0.6730 - val_accuracy: 0.5281 - val_loss: 0.6794\n",
            "Epoch 37/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5803 - loss: 0.6718 - val_accuracy: 0.5281 - val_loss: 0.6794\n",
            "Epoch 38/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5569 - loss: 0.6708 - val_accuracy: 0.5281 - val_loss: 0.6793\n",
            "Epoch 39/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5738 - loss: 0.6731 - val_accuracy: 0.5281 - val_loss: 0.6793\n",
            "Epoch 40/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5843 - loss: 0.6680 - val_accuracy: 0.5281 - val_loss: 0.6793\n",
            "Epoch 41/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5899 - loss: 0.6694 - val_accuracy: 0.5281 - val_loss: 0.6792\n",
            "Epoch 42/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5705 - loss: 0.6718 - val_accuracy: 0.5281 - val_loss: 0.6792\n",
            "Epoch 43/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5791 - loss: 0.6706 - val_accuracy: 0.5281 - val_loss: 0.6792\n",
            "Epoch 44/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5643 - loss: 0.6728 - val_accuracy: 0.5281 - val_loss: 0.6791\n",
            "Epoch 45/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5781 - loss: 0.6709 - val_accuracy: 0.5281 - val_loss: 0.6791\n",
            "Epoch 46/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5631 - loss: 0.6727 - val_accuracy: 0.5281 - val_loss: 0.6791\n",
            "Epoch 47/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5731 - loss: 0.6703 - val_accuracy: 0.5312 - val_loss: 0.6791\n",
            "Epoch 48/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5826 - loss: 0.6711 - val_accuracy: 0.5312 - val_loss: 0.6790\n",
            "Epoch 49/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5883 - loss: 0.6693 - val_accuracy: 0.5312 - val_loss: 0.6790\n",
            "Epoch 50/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5722 - loss: 0.6693 - val_accuracy: 0.5312 - val_loss: 0.6790\n",
            "Epoch 51/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5812 - loss: 0.6718 - val_accuracy: 0.5312 - val_loss: 0.6789\n",
            "Epoch 52/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5821 - loss: 0.6728 - val_accuracy: 0.5312 - val_loss: 0.6789\n",
            "Epoch 53/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5852 - loss: 0.6675 - val_accuracy: 0.5344 - val_loss: 0.6789\n",
            "Epoch 54/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5887 - loss: 0.6694 - val_accuracy: 0.5375 - val_loss: 0.6788\n",
            "Epoch 55/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5800 - loss: 0.6715 - val_accuracy: 0.5375 - val_loss: 0.6788\n",
            "Epoch 56/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5521 - loss: 0.6750 - val_accuracy: 0.5375 - val_loss: 0.6788\n",
            "Epoch 57/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5706 - loss: 0.6747 - val_accuracy: 0.5375 - val_loss: 0.6787\n",
            "Epoch 58/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5866 - loss: 0.6717 - val_accuracy: 0.5375 - val_loss: 0.6787\n",
            "Epoch 59/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5828 - loss: 0.6663 - val_accuracy: 0.5375 - val_loss: 0.6787\n",
            "Epoch 60/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5764 - loss: 0.6723 - val_accuracy: 0.5375 - val_loss: 0.6786\n",
            "Epoch 61/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5992 - loss: 0.6675 - val_accuracy: 0.5375 - val_loss: 0.6786\n",
            "Epoch 62/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5906 - loss: 0.6697 - val_accuracy: 0.5406 - val_loss: 0.6786\n",
            "Epoch 63/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5484 - loss: 0.6751 - val_accuracy: 0.5375 - val_loss: 0.6785\n",
            "Epoch 64/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5927 - loss: 0.6675 - val_accuracy: 0.5375 - val_loss: 0.6785\n",
            "Epoch 65/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5814 - loss: 0.6717 - val_accuracy: 0.5375 - val_loss: 0.6785\n",
            "Epoch 66/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5891 - loss: 0.6642 - val_accuracy: 0.5375 - val_loss: 0.6784\n",
            "Epoch 67/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5859 - loss: 0.6716 - val_accuracy: 0.5406 - val_loss: 0.6784\n",
            "Epoch 68/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5538 - loss: 0.6765 - val_accuracy: 0.5406 - val_loss: 0.6784\n",
            "Epoch 69/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5819 - loss: 0.6694 - val_accuracy: 0.5406 - val_loss: 0.6783\n",
            "Epoch 70/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5808 - loss: 0.6695 - val_accuracy: 0.5406 - val_loss: 0.6783\n",
            "Epoch 71/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5756 - loss: 0.6730 - val_accuracy: 0.5406 - val_loss: 0.6783\n",
            "Epoch 72/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5754 - loss: 0.6718 - val_accuracy: 0.5406 - val_loss: 0.6783\n",
            "Epoch 73/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5839 - loss: 0.6658 - val_accuracy: 0.5406 - val_loss: 0.6782\n",
            "Epoch 74/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5819 - loss: 0.6704 - val_accuracy: 0.5406 - val_loss: 0.6782\n",
            "Epoch 75/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5747 - loss: 0.6705 - val_accuracy: 0.5437 - val_loss: 0.6782\n",
            "Epoch 76/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5822 - loss: 0.6673 - val_accuracy: 0.5437 - val_loss: 0.6781\n",
            "Epoch 77/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5887 - loss: 0.6711 - val_accuracy: 0.5437 - val_loss: 0.6781\n",
            "Epoch 78/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5756 - loss: 0.6715 - val_accuracy: 0.5437 - val_loss: 0.6781\n",
            "Epoch 79/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5822 - loss: 0.6713 - val_accuracy: 0.5437 - val_loss: 0.6780\n",
            "Epoch 80/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5834 - loss: 0.6726 - val_accuracy: 0.5437 - val_loss: 0.6780\n",
            "Epoch 81/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5982 - loss: 0.6673 - val_accuracy: 0.5437 - val_loss: 0.6780\n",
            "Epoch 82/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5992 - loss: 0.6700 - val_accuracy: 0.5437 - val_loss: 0.6779\n",
            "Epoch 83/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5909 - loss: 0.6716 - val_accuracy: 0.5469 - val_loss: 0.6779\n",
            "Epoch 84/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5825 - loss: 0.6746 - val_accuracy: 0.5469 - val_loss: 0.6779\n",
            "Epoch 85/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5719 - loss: 0.6731 - val_accuracy: 0.5469 - val_loss: 0.6778\n",
            "Epoch 86/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5854 - loss: 0.6686 - val_accuracy: 0.5469 - val_loss: 0.6778\n",
            "Epoch 87/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5893 - loss: 0.6721 - val_accuracy: 0.5469 - val_loss: 0.6778\n",
            "Epoch 88/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5887 - loss: 0.6688 - val_accuracy: 0.5469 - val_loss: 0.6777\n",
            "Epoch 89/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5760 - loss: 0.6724 - val_accuracy: 0.5469 - val_loss: 0.6777\n",
            "Epoch 90/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5745 - loss: 0.6724 - val_accuracy: 0.5469 - val_loss: 0.6777\n",
            "Epoch 91/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5925 - loss: 0.6708 - val_accuracy: 0.5469 - val_loss: 0.6776\n",
            "Epoch 92/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5910 - loss: 0.6698 - val_accuracy: 0.5469 - val_loss: 0.6776\n",
            "Epoch 93/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5951 - loss: 0.6699 - val_accuracy: 0.5469 - val_loss: 0.6776\n",
            "Epoch 94/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5804 - loss: 0.6703 - val_accuracy: 0.5469 - val_loss: 0.6775\n",
            "Epoch 95/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5917 - loss: 0.6677 - val_accuracy: 0.5469 - val_loss: 0.6775\n",
            "Epoch 96/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5922 - loss: 0.6685 - val_accuracy: 0.5469 - val_loss: 0.6775\n",
            "Epoch 97/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5719 - loss: 0.6707 - val_accuracy: 0.5469 - val_loss: 0.6775\n",
            "Epoch 98/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6008 - loss: 0.6685 - val_accuracy: 0.5469 - val_loss: 0.6774\n",
            "Epoch 99/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6016 - loss: 0.6702 - val_accuracy: 0.5469 - val_loss: 0.6774\n",
            "Epoch 100/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5968 - loss: 0.6715 - val_accuracy: 0.5469 - val_loss: 0.6774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
            "Testing Accuracy: 0.546875\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.91      0.64       141\n",
            "           1       0.79      0.26      0.39       179\n",
            "\n",
            "    accuracy                           0.55       320\n",
            "   macro avg       0.64      0.59      0.51       320\n",
            "weighted avg       0.66      0.55      0.50       320\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Prediction: Bad Quality\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data_url = \"/content/winequality-red.csv\"\n",
        "df = pd.read_csv(data_url)\n",
        "\n",
        "# Preprocessing\n",
        "y = df['quality']\n",
        "X = df.drop(columns=['quality'])\n",
        "y = np.where(y >= 6, 1, 0)  # Convert to binary classification\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build ANN Model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    keras.layers.Dense(20, activation='relu'),\n",
        "    keras.layers.Dense(25, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "# Compile model\n",
        "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save model\n",
        "model.save(\"wine_quality_model.h5\")\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Testing Accuracy: {accuracy}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Precision, Recall, F1-score\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Deploy model\n",
        "loaded_model = keras.models.load_model(\"wine_quality_model.h5\")\n",
        "def predict_wine_quality(sample):\n",
        "    sample = scaler.transform([sample])\n",
        "    prediction = loaded_model.predict(sample)\n",
        "    return \"Good Quality\" if prediction > 0.5 else \"Bad Quality\"\n",
        "\n",
        "# Example Prediction\n",
        "sample_data = X_test[0]\n",
        "print(\"Sample Prediction:\", predict_wine_quality(sample_data))"
      ]
    }
  ]
}